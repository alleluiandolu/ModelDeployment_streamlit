# -*- coding: utf-8 -*-
"""Modeling - B.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qEJci4na3AL04davnglUMl89jpakdwUC

Nama: Alleluia Rehuellah Alefika Ndolu

NIM: 2602056334

# **Soal**
2) Mengubah proses training model terbaik yang telah diperoleh dalam
pemodelan di atas dalam format OOP.

# Jawaban
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
import xgboost as xgb
from sklearn.metrics import classification_report
import pickle

class ModelHandler:
    def __init__(self, input_data, output_data):
        self.input_data = input_data
        self.output_data = output_data
        self.x_train, self.x_test, self.y_train, self.y_test, self.y_predict = [None] * 5
        self.preprocessData()
        self.splitData()
        self.handleMissingValues()
        self.labelEncode()
        self.binaryEncode()
        self.scaleData()
        self.trainXGBModel()
        self.makeXGBPrediction()
        self.createXGBReport()
        self.saveModels()

    def preprocessData(self):
        self.input_data['CreditScore'].fillna(self.input_data['CreditScore'].median(), inplace=True)
        self.input_data = self.input_data.drop(['Unnamed: 0', 'id', 'CustomerId', 'Surname'], axis=1)

    def splitData(self, test_size=0.2, random_state=42):
        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(
            self.input_data, self.output_data, test_size=test_size, random_state=random_state
        )

    def handleMissingValues(self):
        self.x_train['CreditScore'].fillna(self.x_train['CreditScore'].median(), inplace=True)
        self.x_test['CreditScore'].fillna(self.x_train['CreditScore'].median(), inplace=True)

    def labelEncode(self):
        self.label_encoder = LabelEncoder()
        self.x_train['Geography'] = self.label_encoder.fit_transform(self.x_train['Geography'])
        self.x_test['Geography'] = self.label_encoder.transform(self.x_test['Geography'])

    def binaryEncode(self):
        self.gender_mapping = {"Male": 1, "Female": 0}
        self.x_train['Gender'] = self.x_train['Gender'].map(self.gender_mapping)
        self.x_test['Gender'] = self.x_test['Gender'].map(self.gender_mapping)

    def scaleData(self):
        self.sc = StandardScaler()
        cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary'
        ]
        self.x_train[cols] = self.sc.fit_transform(self.x_train[cols])
        self.x_test[cols] = self.sc.transform(self.x_test[cols])

    def trainXGBModel(self):
        self.xgb_model = xgb.XGBClassifier(gamma=0.2, max_depth=4, n_estimators=50)
        self.xgb_model.fit(self.x_train, self.y_train)

    def makeXGBPrediction(self):
        self.y_predict_XGB = self.xgb_model.predict(self.x_test)

    def createXGBReport(self):
        print("\nXGBoost Classification Report:\n")
        print(classification_report(self.y_test, self.y_predict_XGB))

    def saveModels(self):
        # Save label_encode, scaling, and gender_encode using pickle
        with open('label_encode.pkl', 'wb') as f:
            pickle.dump(self.label_encoder, f)

        with open('gender_encode.pkl', 'wb') as f:
            pickle.dump(self.gender_mapping, f)

        with open('XGBoost.pkl', 'wb') as f:
            pickle.dump(self.xgb_model, f)

input_data = pd.read_csv('data_D.csv')
output_data = input_data['churn']
input_data.drop('churn', axis=1, inplace=True)

model_handler = ModelHandler(input_data, output_data)